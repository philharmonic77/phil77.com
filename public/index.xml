<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>philharmonic77&#39;s blog</title>
    <link>/</link>
    <description>Recent content on philharmonic77&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 12 Jun 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>聚类分析在有监督学习里的应用</title>
      <link>/post/cluster-in-supervised/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/cluster-in-supervised/</guid>
      
        <description>

&lt;h3 id=&#34;先聚类再分类&#34;&gt;先聚类再分类&lt;/h3&gt;

&lt;p&gt;一般用于分析人员本身具有行业知识，认为聚类的处理是必要的情况下，因为一般来说有监督学习利用了标签信息，效果是优于无监督学习的。&lt;/p&gt;

&lt;p&gt;该方法训练很耗时，且数据集太小时容易产生过拟合，慎用。另外，在自动化流程中，需要谨慎控制每一类的样本量。&lt;/p&gt;

&lt;p&gt;此文档中，聚类方法均使用kmeans，后续可拓展。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;参考文献：&lt;a href=&#34;https://arxiv.org/abs/1509.06163&#34;&gt;The Utility of Clustering in Prediction Tasks&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;简单数据集测试&#34;&gt;简单数据集测试&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;数据集 &lt;a href=&#34;https://www.kaggle.com/c/titanic/data&#34;&gt;kaggle-Titanic&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;先做&lt;a href=&#34;https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python&#34;&gt;特征提取&lt;/a&gt;，得到全部都是数值型变量，且有解释性的训练数据和测试数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/image/Using Clustering in the Pre-processing Procedure/training set.PNG&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;1-直接采用分类模型&#34;&gt;1. 直接采用分类模型&lt;/h5&gt;

&lt;p&gt;将training dataset用&lt;a href=&#34;http://stage20.newa-tech.com:22000/modeling/169/2&#34;&gt;R2-Learn&lt;/a&gt;进行训练，选择推荐的ensemble模型，
并在&lt;a href=&#34;http://stage20.newa-tech.com:22000/deploy/169&#34;&gt;deployment环节&lt;/a&gt;使用test dataset，得到y值的预测之后，上传到kaggle进行评分。&lt;/p&gt;

&lt;p&gt;采用auto-sklearn 0.3.0以默认参数训练5min，同样使用kaggle评分。结果汇总如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类别&lt;/th&gt;
&lt;th&gt;R2-Learn&lt;/th&gt;
&lt;th&gt;AutoML 0.3.0&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;训练时间&lt;/td&gt;
&lt;td&gt;5 min&lt;/td&gt;
&lt;td&gt;5 min&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;训练集AUC&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kaggle accuracy&lt;/td&gt;
&lt;td&gt;0.732&lt;/td&gt;
&lt;td&gt;0.775&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&#34;2-先对数据集进行聚类-再对各个类进行训练&#34;&gt;2. 先对数据集进行聚类，再对各个类进行训练&lt;/h5&gt;

&lt;p&gt;总体思路见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/image/Using Clustering in the Pre-processing Procedure/screen shot of method.PNG&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h6 id=&#34;2-1-不使用ensemble的情况&#34;&gt;2.1 不使用ensemble的情况&lt;/h6&gt;

&lt;p&gt;k依次取1,2,3,&amp;hellip;, 每一轮计算中，先将training data标准化，再聚成k类，然后分别使用auto-sklearn 0.3.0/random forest训练，最终汇集预测值，然后计算AUC。完成全部计算后，对比不同k值对预测的影响。找到预测效果较好的设定，并尝试解释聚类的合理性。&lt;/p&gt;

&lt;p&gt;此例中，样本量较小，所以至多考虑3类。在样本量较大时，可以加入k值的自动选择机制。&lt;/p&gt;

&lt;p&gt;在此例中， 使用先聚类在分类的方法&lt;del&gt;未见明显作用&lt;/del&gt;，原因可能是数据量太小，聚类之后进一步缩小了样本量，导致模型&lt;strong&gt;过拟合&lt;/strong&gt;。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类别&lt;/th&gt;
&lt;th&gt;k=1&lt;/th&gt;
&lt;th&gt;k=2&lt;/th&gt;
&lt;th&gt;k=3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;轮廓系数（+）&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;0.285&lt;/td&gt;
&lt;td&gt;0.307&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;训练集AUC&lt;/td&gt;
&lt;td&gt;0.837&lt;/td&gt;
&lt;td&gt;0.874&lt;/td&gt;
&lt;td&gt;0.918&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;训练集accuracy&lt;/td&gt;
&lt;td&gt;0.852&lt;/td&gt;
&lt;td&gt;0.889&lt;/td&gt;
&lt;td&gt;0.928&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;kaggle accuracy&lt;/td&gt;
&lt;td&gt;0.780&lt;/td&gt;
&lt;td&gt;0.770&lt;/td&gt;
&lt;td&gt;0.713&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;此外，一个自然的想法是，数据集本身是否存在一定的聚集模式。这里使用manifold learning将原始数据中的X值降维可视化，并使用轮廓系数最大情形下的聚类标签着色，得到下图。可见，该数据集并不具有天然可分性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/image/Using Clustering in the Pre-processing Procedure/t-SNE of Titanic clean.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;2-2-更换数据集&#34;&gt;2.2 更换数据集&lt;/h5&gt;

&lt;p&gt;于是，我们改换数据量更大的数据进行实验,或者有明显聚集性的数据继续实验。&lt;/p&gt;

&lt;h6 id=&#34;2-2-1&#34;&gt;2.2.1&lt;/h6&gt;

&lt;p&gt;数据集：&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients&#34;&gt;default of credit card clients&lt;/a&gt;， 3w行，25列。&lt;/p&gt;

&lt;p&gt;训练集，测试集划分：70%， 30%。
使用k-means进行聚类，在k=2时，轮廓系数达到最高。降维可视化后的数据，仍是不具有明显聚集性的数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/image/Using Clustering in the Pre-processing Procedure/credit_cluster.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;训练时长统一为500s。结果并未显示聚类对效果有改进，相反时间耗费大大增加。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类别&lt;/th&gt;
&lt;th&gt;k=1&lt;/th&gt;
&lt;th&gt;k=2&lt;/th&gt;
&lt;th&gt;k=3&lt;/th&gt;
&lt;th&gt;k=4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;轮廓系数（+）&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;0.355&lt;/td&gt;
&lt;td&gt;0.188&lt;/td&gt;
&lt;td&gt;0.165&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;训练集AUC&lt;/td&gt;
&lt;td&gt;0.837&lt;/td&gt;
&lt;td&gt;0.880&lt;/td&gt;
&lt;td&gt;0.770&lt;/td&gt;
&lt;td&gt;0.864&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;训练集accuracy&lt;/td&gt;
&lt;td&gt;0.827&lt;/td&gt;
&lt;td&gt;0.864&lt;/td&gt;
&lt;td&gt;0.837&lt;/td&gt;
&lt;td&gt;0.880&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;测试集AUC&lt;/td&gt;
&lt;td&gt;0.784&lt;/td&gt;
&lt;td&gt;0.752&lt;/td&gt;
&lt;td&gt;0.702&lt;/td&gt;
&lt;td&gt;0.713&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;测试集accuracy&lt;/td&gt;
&lt;td&gt;0.822&lt;/td&gt;
&lt;td&gt;0.819&lt;/td&gt;
&lt;td&gt;0.824&lt;/td&gt;
&lt;td&gt;0.818&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h6 id=&#34;2-2-2&#34;&gt;2.2.2&lt;/h6&gt;

&lt;p&gt;数据集：&lt;a href=&#34;https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/&#34;&gt;Abalone&lt;/a&gt;，4177行，9列。&lt;/p&gt;

&lt;p&gt;训练集，测试集划分：70%， 30%&lt;/p&gt;

&lt;p&gt;$$\displaystyle\frac{x+y}{y+z}$$&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>